{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "692e361b",
   "metadata": {},
   "source": [
    "# How to run a prompt plugins from file\n",
    "\n",
    "Now that you're familiar with Kernel basics, let's see how the kernel allows you to run Prompt Plugins and Prompt Functions stored on disk.\n",
    "\n",
    "A Prompt Plugin is a collection of Semantic Functions, where each function is defined with natural language that can be provided with a text file.\n",
    "\n",
    "Refer to our [glossary](https://github.com/microsoft/semantic-kernel/blob/main/docs/GLOSSARY.md) for an in-depth guide to the terms.\n",
    "\n",
    "The repository includes some examples under the [samples](https://github.com/microsoft/semantic-kernel/tree/main/samples) folder.\n",
    "\n",
    "For instance, [this](../../../prompt_template_samples/FunPlugin/Joke/skprompt.txt) is the **Joke function** part of the **FunPlugin plugin**:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3feecb6e",
   "metadata": {},
   "source": [
    "Import Semantic Kernel SDK from pypi.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32187534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: semantic-kernel in /Users/mfilipav/dev/semantic-kernel/venv/lib/python3.11/site-packages (1.28.1)\n",
      "Requirement already satisfied: aiohttp~=3.8 in /Users/mfilipav/dev/semantic-kernel/venv/lib/python3.11/site-packages (from semantic-kernel) (3.11.17)\n",
      "Requirement already satisfied: cloudevents~=1.0 in /Users/mfilipav/dev/semantic-kernel/venv/lib/python3.11/site-packages (from semantic-kernel) (1.11.0)\n",
      "Requirement already satisfied: pydantic!=2.10.0,!=2.10.1,!=2.10.2,!=2.10.3,<2.12,>=2.0 in /Users/mfilipav/dev/semantic-kernel/venv/lib/python3.11/site-packages (from semantic-kernel) (2.11.3)\n",
      "Requirement already satisfied: pydantic-settings~=2.0 in /Users/mfilipav/dev/semantic-kernel/venv/lib/python3.11/site-packages (from semantic-kernel) (2.9.1)\n",
      "Requirement already satisfied: defusedxml~=0.7 in /Users/mfilipav/dev/semantic-kernel/venv/lib/python3.11/site-packages (from semantic-kernel) (0.7.1)\n",
      "Requirement already satisfied: azure-identity>=1.13 in /Users/mfilipav/dev/semantic-kernel/venv/lib/python3.11/site-packages (from semantic-kernel) (1.21.0)\n",
      "Requirement already satisfied: numpy>=1.25.0 in /Users/mfilipav/dev/semantic-kernel/venv/lib/python3.11/site-packages (from semantic-kernel) (2.2.5)\n",
      "Requirement already satisfied: openai>=1.67 in /Users/mfilipav/dev/semantic-kernel/venv/lib/python3.11/site-packages (from semantic-kernel) (1.75.0)\n",
      "Requirement already satisfied: openapi_core<0.20,>=0.18 in /Users/mfilipav/dev/semantic-kernel/venv/lib/python3.11/site-packages (from semantic-kernel) (0.19.5)\n",
      "Requirement already satisfied: websockets<16,>=13 in /Users/mfilipav/dev/semantic-kernel/venv/lib/python3.11/site-packages (from semantic-kernel) (15.0.1)\n",
      "Requirement already satisfied: aiortc>=1.9.0 in /Users/mfilipav/dev/semantic-kernel/venv/lib/python3.11/site-packages (from semantic-kernel) (1.11.0)\n",
      "Requirement already satisfied: opentelemetry-api~=1.24 in /Users/mfilipav/dev/semantic-kernel/venv/lib/python3.11/site-packages (from semantic-kernel) (1.32.1)\n",
      "Requirement already satisfied: opentelemetry-sdk~=1.24 in /Users/mfilipav/dev/semantic-kernel/venv/lib/python3.11/site-packages (from semantic-kernel) (1.32.1)\n",
      "Requirement already satisfied: prance~=23.6.21.0 in /Users/mfilipav/dev/semantic-kernel/venv/lib/python3.11/site-packages (from semantic-kernel) (23.6.21.0)\n",
      "Requirement already satisfied: pybars4~=0.9 in /Users/mfilipav/dev/semantic-kernel/venv/lib/python3.11/site-packages (from semantic-kernel) (0.9.13)\n",
      "Requirement already satisfied: jinja2~=3.1 in /Users/mfilipav/dev/semantic-kernel/venv/lib/python3.11/site-packages (from semantic-kernel) (3.1.6)\n",
      "Requirement already satisfied: nest-asyncio~=1.6 in /Users/mfilipav/dev/semantic-kernel/venv/lib/python3.11/site-packages (from semantic-kernel) (1.6.0)\n",
      "Requirement already satisfied: scipy>=1.15.1 in /Users/mfilipav/dev/semantic-kernel/venv/lib/python3.11/site-packages (from semantic-kernel) (1.15.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Users/mfilipav/dev/semantic-kernel/venv/lib/python3.11/site-packages (from aiohttp~=3.8->semantic-kernel) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/mfilipav/dev/semantic-kernel/venv/lib/python3.11/site-packages (from aiohttp~=3.8->semantic-kernel) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/mfilipav/dev/semantic-kernel/venv/lib/python3.11/site-packages (from aiohttp~=3.8->semantic-kernel) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/mfilipav/dev/semantic-kernel/venv/lib/python3.11/site-packages (from aiohttp~=3.8->semantic-kernel) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/mfilipav/dev/semantic-kernel/venv/lib/python3.11/site-packages (from aiohttp~=3.8->semantic-kernel) (6.4.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/mfilipav/dev/semantic-kernel/venv/lib/python3.11/site-packages (from aiohttp~=3.8->semantic-kernel) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/mfilipav/dev/semantic-kernel/venv/lib/python3.11/site-packages (from aiohttp~=3.8->semantic-kernel) (1.20.0)\n",
      "Requirement already satisfied: aioice<1.0.0,>=0.9.0 in /Users/mfilipav/dev/semantic-kernel/venv/lib/python3.11/site-packages (from aiortc>=1.9.0->semantic-kernel) (0.10.1)\n",
      "Requirement already satisfied: av<15.0.0,>=14.0.0 in /Users/mfilipav/dev/semantic-kernel/venv/lib/python3.11/site-packages (from aiortc>=1.9.0->semantic-kernel) (14.3.0)\n",
      "Requirement already satisfied: cffi>=1.0.0 in /Users/mfilipav/dev/semantic-kernel/venv/lib/python3.11/site-packages (from aiortc>=1.9.0->semantic-kernel) (1.17.1)\n",
      "Requirement already satisfied: cryptography>=44.0.0 in /Users/mfilipav/dev/semantic-kernel/venv/lib/python3.11/site-packages (from aiortc>=1.9.0->semantic-kernel) (44.0.2)\n",
      "Requirement already satisfied: google-crc32c>=1.1 in /Users/mfilipav/dev/semantic-kernel/venv/lib/python3.11/site-packages (from aiortc>=1.9.0->semantic-kernel) (1.7.1)\n",
      "Requirement already satisfied: pyee>=13.0.0 in /Users/mfilipav/dev/semantic-kernel/venv/lib/python3.11/site-packages (from aiortc>=1.9.0->semantic-kernel) (13.0.0)\n",
      "Requirement already satisfied: pylibsrtp>=0.10.0 in /Users/mfilipav/dev/semantic-kernel/venv/lib/python3.11/site-packages (from aiortc>=1.9.0->semantic-kernel) (0.12.0)\n",
      "Requirement already satisfied: pyopenssl>=25.0.0 in /Users/mfilipav/dev/semantic-kernel/venv/lib/python3.11/site-packages (from aiortc>=1.9.0->semantic-kernel) (25.0.0)\n",
      "Requirement already satisfied: azure-core>=1.31.0 in /Users/mfilipav/dev/semantic-kernel/venv/lib/python3.11/site-packages (from azure-identity>=1.13->semantic-kernel) (1.33.0)\n",
      "Requirement already satisfied: msal>=1.30.0 in /Users/mfilipav/dev/semantic-kernel/venv/lib/python3.11/site-packages (from azure-identity>=1.13->semantic-kernel) (1.32.0)\n",
      "Requirement already satisfied: msal-extensions>=1.2.0 in /Users/mfilipav/dev/semantic-kernel/venv/lib/python3.11/site-packages (from azure-identity>=1.13->semantic-kernel) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /Users/mfilipav/dev/semantic-kernel/venv/lib/python3.11/site-packages (from azure-identity>=1.13->semantic-kernel) (4.13.2)\n",
      "Requirement already satisfied: deprecation<3.0,>=2.0 in /Users/mfilipav/dev/semantic-kernel/venv/lib/python3.11/site-packages (from cloudevents~=1.0->semantic-kernel) (2.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/mfilipav/dev/semantic-kernel/venv/lib/python3.11/site-packages (from jinja2~=3.1->semantic-kernel) (3.0.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/mfilipav/dev/semantic-kernel/venv/lib/python3.11/site-packages (from openai>=1.67->semantic-kernel) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/mfilipav/dev/semantic-kernel/venv/lib/python3.11/site-packages (from openai>=1.67->semantic-kernel) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/mfilipav/dev/semantic-kernel/venv/lib/python3.11/site-packages (from openai>=1.67->semantic-kernel) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/mfilipav/dev/semantic-kernel/venv/lib/python3.11/site-packages (from openai>=1.67->semantic-kernel) (0.9.0)\n",
      "Requirement already satisfied: sniffio in /Users/mfilipav/dev/semantic-kernel/venv/lib/python3.11/site-packages (from openai>=1.67->semantic-kernel) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /Users/mfilipav/dev/semantic-kernel/venv/lib/python3.11/site-packages (from openai>=1.67->semantic-kernel) (4.67.1)\n",
      "Requirement already satisfied: isodate in /Users/mfilipav/dev/semantic-kernel/venv/lib/python3.11/site-packages (from openapi_core<0.20,>=0.18->semantic-kernel) (0.7.2)\n",
      "Requirement already satisfied: jsonschema<5.0.0,>=4.18.0 in /Users/mfilipav/dev/semantic-kernel/venv/lib/python3.11/site-packages (from openapi_core<0.20,>=0.18->semantic-kernel) (4.23.0)\n",
      "Requirement already satisfied: jsonschema-path<0.4.0,>=0.3.1 in /Users/mfilipav/dev/semantic-kernel/venv/lib/python3.11/site-packages (from openapi_core<0.20,>=0.18->semantic-kernel) (0.3.4)\n",
      "Requirement already satisfied: more-itertools in /Users/mfilipav/dev/semantic-kernel/venv/lib/python3.11/site-packages (from openapi_core<0.20,>=0.18->semantic-kernel) (10.6.0)\n",
      "Requirement already satisfied: openapi-schema-validator<0.7.0,>=0.6.0 in /Users/mfilipav/dev/semantic-kernel/venv/lib/python3.11/site-packages (from openapi_core<0.20,>=0.18->semantic-kernel) (0.6.3)\n",
      "Requirement already satisfied: openapi-spec-validator<0.8.0,>=0.7.1 in /Users/mfilipav/dev/semantic-kernel/venv/lib/python3.11/site-packages (from openapi_core<0.20,>=0.18->semantic-kernel) (0.7.1)\n",
      "Requirement already satisfied: parse in /Users/mfilipav/dev/semantic-kernel/venv/lib/python3.11/site-packages (from openapi_core<0.20,>=0.18->semantic-kernel) (1.20.2)\n",
      "Requirement already satisfied: werkzeug<3.1.2 in /Users/mfilipav/dev/semantic-kernel/venv/lib/python3.11/site-packages (from openapi_core<0.20,>=0.18->semantic-kernel) (3.1.1)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in /Users/mfilipav/dev/semantic-kernel/venv/lib/python3.11/site-packages (from opentelemetry-api~=1.24->semantic-kernel) (1.2.18)\n",
      "Requirement already satisfied: importlib-metadata<8.7.0,>=6.0 in /Users/mfilipav/dev/semantic-kernel/venv/lib/python3.11/site-packages (from opentelemetry-api~=1.24->semantic-kernel) (8.6.1)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.53b1 in /Users/mfilipav/dev/semantic-kernel/venv/lib/python3.11/site-packages (from opentelemetry-sdk~=1.24->semantic-kernel) (0.53b1)\n",
      "Requirement already satisfied: chardet>=3.0 in /Users/mfilipav/dev/semantic-kernel/venv/lib/python3.11/site-packages (from prance~=23.6.21.0->semantic-kernel) (5.2.0)\n",
      "Requirement already satisfied: ruamel.yaml>=0.17.10 in /Users/mfilipav/dev/semantic-kernel/venv/lib/python3.11/site-packages (from prance~=23.6.21.0->semantic-kernel) (0.18.10)\n",
      "Requirement already satisfied: requests>=2.25 in /Users/mfilipav/dev/semantic-kernel/venv/lib/python3.11/site-packages (from prance~=23.6.21.0->semantic-kernel) (2.32.3)\n",
      "Requirement already satisfied: six~=1.15 in /Users/mfilipav/dev/semantic-kernel/venv/lib/python3.11/site-packages (from prance~=23.6.21.0->semantic-kernel) (1.17.0)\n",
      "Requirement already satisfied: packaging>=21.3 in /Users/mfilipav/dev/semantic-kernel/venv/lib/python3.11/site-packages (from prance~=23.6.21.0->semantic-kernel) (25.0)\n",
      "Requirement already satisfied: PyMeta3>=0.5.1 in /Users/mfilipav/dev/semantic-kernel/venv/lib/python3.11/site-packages (from pybars4~=0.9->semantic-kernel) (0.5.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/mfilipav/dev/semantic-kernel/venv/lib/python3.11/site-packages (from pydantic!=2.10.0,!=2.10.1,!=2.10.2,!=2.10.3,<2.12,>=2.0->semantic-kernel) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in /Users/mfilipav/dev/semantic-kernel/venv/lib/python3.11/site-packages (from pydantic!=2.10.0,!=2.10.1,!=2.10.2,!=2.10.3,<2.12,>=2.0->semantic-kernel) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/mfilipav/dev/semantic-kernel/venv/lib/python3.11/site-packages (from pydantic!=2.10.0,!=2.10.1,!=2.10.2,!=2.10.3,<2.12,>=2.0->semantic-kernel) (0.4.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /Users/mfilipav/dev/semantic-kernel/venv/lib/python3.11/site-packages (from pydantic-settings~=2.0->semantic-kernel) (1.1.0)\n",
      "Requirement already satisfied: dnspython>=2.0.0 in /Users/mfilipav/dev/semantic-kernel/venv/lib/python3.11/site-packages (from aioice<1.0.0,>=0.9.0->aiortc>=1.9.0->semantic-kernel) (2.7.0)\n",
      "Requirement already satisfied: ifaddr>=0.2.0 in /Users/mfilipav/dev/semantic-kernel/venv/lib/python3.11/site-packages (from aioice<1.0.0,>=0.9.0->aiortc>=1.9.0->semantic-kernel) (0.2.0)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/mfilipav/dev/semantic-kernel/venv/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai>=1.67->semantic-kernel) (3.10)\n",
      "Requirement already satisfied: pycparser in /Users/mfilipav/dev/semantic-kernel/venv/lib/python3.11/site-packages (from cffi>=1.0.0->aiortc>=1.9.0->semantic-kernel) (2.22)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /Users/mfilipav/dev/semantic-kernel/venv/lib/python3.11/site-packages (from deprecated>=1.2.6->opentelemetry-api~=1.24->semantic-kernel) (1.17.2)\n",
      "Requirement already satisfied: certifi in /Users/mfilipav/dev/semantic-kernel/venv/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai>=1.67->semantic-kernel) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/mfilipav/dev/semantic-kernel/venv/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai>=1.67->semantic-kernel) (1.0.8)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/mfilipav/dev/semantic-kernel/venv/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1.67->semantic-kernel) (0.14.0)\n",
      "Requirement already satisfied: zipp>=3.20 in /Users/mfilipav/dev/semantic-kernel/venv/lib/python3.11/site-packages (from importlib-metadata<8.7.0,>=6.0->opentelemetry-api~=1.24->semantic-kernel) (3.21.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /Users/mfilipav/dev/semantic-kernel/venv/lib/python3.11/site-packages (from jsonschema<5.0.0,>=4.18.0->openapi_core<0.20,>=0.18->semantic-kernel) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /Users/mfilipav/dev/semantic-kernel/venv/lib/python3.11/site-packages (from jsonschema<5.0.0,>=4.18.0->openapi_core<0.20,>=0.18->semantic-kernel) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /Users/mfilipav/dev/semantic-kernel/venv/lib/python3.11/site-packages (from jsonschema<5.0.0,>=4.18.0->openapi_core<0.20,>=0.18->semantic-kernel) (0.24.0)\n",
      "Requirement already satisfied: PyYAML>=5.1 in /Users/mfilipav/dev/semantic-kernel/venv/lib/python3.11/site-packages (from jsonschema-path<0.4.0,>=0.3.1->openapi_core<0.20,>=0.18->semantic-kernel) (6.0.2)\n",
      "Requirement already satisfied: pathable<0.5.0,>=0.4.1 in /Users/mfilipav/dev/semantic-kernel/venv/lib/python3.11/site-packages (from jsonschema-path<0.4.0,>=0.3.1->openapi_core<0.20,>=0.18->semantic-kernel) (0.4.4)\n",
      "Requirement already satisfied: PyJWT[crypto]<3,>=1.0.0 in /Users/mfilipav/dev/semantic-kernel/venv/lib/python3.11/site-packages (from msal>=1.30.0->azure-identity>=1.13->semantic-kernel) (2.10.1)\n",
      "Requirement already satisfied: rfc3339-validator in /Users/mfilipav/dev/semantic-kernel/venv/lib/python3.11/site-packages (from openapi-schema-validator<0.7.0,>=0.6.0->openapi_core<0.20,>=0.18->semantic-kernel) (0.1.4)\n",
      "Requirement already satisfied: lazy-object-proxy<2.0.0,>=1.7.1 in /Users/mfilipav/dev/semantic-kernel/venv/lib/python3.11/site-packages (from openapi-spec-validator<0.8.0,>=0.7.1->openapi_core<0.20,>=0.18->semantic-kernel) (1.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/mfilipav/dev/semantic-kernel/venv/lib/python3.11/site-packages (from requests>=2.25->prance~=23.6.21.0->semantic-kernel) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/mfilipav/dev/semantic-kernel/venv/lib/python3.11/site-packages (from requests>=2.25->prance~=23.6.21.0->semantic-kernel) (2.4.0)\n",
      "Requirement already satisfied: ruamel.yaml.clib>=0.2.7 in /Users/mfilipav/dev/semantic-kernel/venv/lib/python3.11/site-packages (from ruamel.yaml>=0.17.10->prance~=23.6.21.0->semantic-kernel) (0.2.12)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1.28.1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note: if using a virtual environment, do not run this cell\n",
    "%pip install -U semantic-kernel\n",
    "from semantic_kernel import __version__\n",
    "\n",
    "__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc58d362",
   "metadata": {},
   "source": [
    "Initial configuration for the notebook to run properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc1bc941",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure paths are correct for the imports\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "notebook_dir = os.path.abspath(\"\")\n",
    "parent_dir = os.path.dirname(notebook_dir)\n",
    "grandparent_dir = os.path.dirname(parent_dir)\n",
    "\n",
    "\n",
    "sys.path.append(grandparent_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5074884",
   "metadata": {},
   "source": [
    "### Configuring the Kernel\n",
    "\n",
    "Let's get started with the necessary configuration to run Semantic Kernel. For Notebooks, we require a `.env` file with the proper settings for the model you use. Create a new file named `.env` and place it in this directory. Copy the contents of the `.env.example` file from this directory and paste it into the `.env` file that you just created.\n",
    "\n",
    "**NOTE: Please make sure to include `GLOBAL_LLM_SERVICE` set to either OpenAI, AzureOpenAI, or HuggingFace in your .env file. If this setting is not included, the Service will default to AzureOpenAI.**\n",
    "\n",
    "#### Option 1: using OpenAI\n",
    "\n",
    "Add your [OpenAI Key](https://openai.com/product/) key to your `.env` file (org Id only if you have multiple orgs):\n",
    "\n",
    "```\n",
    "GLOBAL_LLM_SERVICE=\"OpenAI\"\n",
    "OPENAI_API_KEY=\"sk-...\"\n",
    "OPENAI_ORG_ID=\"\"\n",
    "OPENAI_CHAT_MODEL_ID=\"\"\n",
    "OPENAI_TEXT_MODEL_ID=\"\"\n",
    "OPENAI_EMBEDDING_MODEL_ID=\"\"\n",
    "```\n",
    "The names should match the names used in the `.env` file, as shown above.\n",
    "\n",
    "#### Option 2: using Azure OpenAI\n",
    "\n",
    "Add your [Azure Open AI Service key](https://learn.microsoft.com/azure/cognitive-services/openai/quickstart?pivots=programming-language-studio) settings to the `.env` file in the same folder:\n",
    "\n",
    "```\n",
    "GLOBAL_LLM_SERVICE=\"AzureOpenAI\"\n",
    "AZURE_OPENAI_API_KEY=\"...\"\n",
    "AZURE_OPENAI_ENDPOINT=\"https://...\"\n",
    "AZURE_OPENAI_CHAT_DEPLOYMENT_NAME=\"...\"\n",
    "AZURE_OPENAI_TEXT_DEPLOYMENT_NAME=\"...\"\n",
    "AZURE_OPENAI_EMBEDDING_DEPLOYMENT_NAME=\"...\"\n",
    "AZURE_OPENAI_API_VERSION=\"...\"\n",
    "```\n",
    "The names should match the names used in the `.env` file, as shown above.\n",
    "\n",
    "For more advanced configuration, please follow the steps outlined in the [setup guide](./CONFIGURING_THE_KERNEL.md)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d7361e",
   "metadata": {},
   "source": [
    "Let's move on to learning what prompts are and how to write them."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f3ce1efe",
   "metadata": {},
   "source": [
    "```\n",
    "WRITE EXACTLY ONE JOKE or HUMOROUS STORY ABOUT THE TOPIC BELOW.\n",
    "JOKE MUST BE:\n",
    "- G RATED\n",
    "- WORKPLACE/FAMILY SAFE\n",
    "NO SEXISM, RACISM OR OTHER BIAS/BIGOTRY.\n",
    "BE CREATIVE AND FUNNY. I WANT TO LAUGH.\n",
    "+++++\n",
    "{{$input}}\n",
    "+++++\n",
    "```\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "afdb96d6",
   "metadata": {},
   "source": [
    "Note the special **`{{$input}}`** token, which is a variable that is automatically passed when invoking the function, commonly referred to as a \"function parameter\".\n",
    "\n",
    "We'll explore later how functions can accept multiple variables, as well as invoke other functions.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c3bd5134",
   "metadata": {},
   "source": [
    "In the same folder you'll notice a second [config.json](../../../prompt_template_samples/FunPlugin/Joke/config.json) file. The file is optional, and is used to set some parameters for large language models like Temperature, TopP, Stop Sequences, etc.\n",
    "\n",
    "```\n",
    "{\n",
    "  \"schema\": 1,\n",
    "  \"description\": \"Generate a funny joke\",\n",
    "  \"execution_settings\": {\n",
    "    \"default\": {\n",
    "      \"max_tokens\": 1000,\n",
    "      \"temperature\": 0.9,\n",
    "      \"top_p\": 0.0,\n",
    "      \"presence_penalty\": 0.0,\n",
    "      \"frequency_penalty\": 0.0\n",
    "    }\n",
    "  },\n",
    "  \"input_variables\": [\n",
    "    {\n",
    "      \"name\": \"input\",\n",
    "      \"description\": \"Joke subject\",\n",
    "      \"default\": \"\"\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"style\",\n",
    "      \"description\": \"Give a hint about the desired joke style\",\n",
    "      \"default\": \"\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\n",
    "```\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "384ff07f",
   "metadata": {},
   "source": [
    "Given a prompt function defined by these files, this is how to load and use a file based prompt function.\n",
    "\n",
    "Load and configure the kernel, as usual, loading also the AI service settings defined in the [Setup notebook](00-getting-started.ipynb):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c0688c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel import Kernel\n",
    "\n",
    "kernel = Kernel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f0788e",
   "metadata": {},
   "source": [
    "We will load our settings and get the LLM service to use for the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82d16ce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using service type: Service.AzureOpenAI\n"
     ]
    }
   ],
   "source": [
    "from services import Service\n",
    "\n",
    "from samples.service_settings import ServiceSettings\n",
    "\n",
    "service_settings = ServiceSettings()\n",
    "\n",
    "# Select a service to use for this notebook (available services: OpenAI, AzureOpenAI, HuggingFace)\n",
    "selectedService = (\n",
    "    Service.AzureOpenAI\n",
    "    if service_settings.global_llm_service is None\n",
    "    else Service(service_settings.global_llm_service.lower())\n",
    ")\n",
    "print(f\"Using service type: {selectedService}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ad7f35",
   "metadata": {},
   "source": [
    "Let's load our settings and validate that the required ones exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fdb865a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using service type: Service.AzureOpenAI\n"
     ]
    }
   ],
   "source": [
    "from services import Service\n",
    "\n",
    "from samples.service_settings import ServiceSettings\n",
    "\n",
    "service_settings = ServiceSettings()\n",
    "\n",
    "# Select a service to use for this notebook (available services: OpenAI, AzureOpenAI, HuggingFace)\n",
    "selectedService = (\n",
    "    Service.AzureOpenAI\n",
    "    if service_settings.global_llm_service is None\n",
    "    else Service(service_settings.global_llm_service.lower())\n",
    ")\n",
    "print(f\"Using service type: {selectedService}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50b4d7a",
   "metadata": {},
   "source": [
    "We now configure our Chat Completion service on the kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0062a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all services so that this cell can be re-run without restarting the kernel\n",
    "kernel.remove_all_services()\n",
    "\n",
    "service_id = None\n",
    "if selectedService == Service.OpenAI:\n",
    "    from semantic_kernel.connectors.ai.open_ai import OpenAIChatCompletion\n",
    "\n",
    "    service_id = \"default\"\n",
    "    kernel.add_service(\n",
    "        OpenAIChatCompletion(\n",
    "            service_id=service_id,\n",
    "        ),\n",
    "    )\n",
    "elif selectedService == Service.AzureOpenAI:\n",
    "    from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion\n",
    "\n",
    "    service_id = \"default\"\n",
    "    kernel.add_service(\n",
    "        AzureChatCompletion(\n",
    "            service_id=service_id,\n",
    "        ),\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fd5ff1f4",
   "metadata": {},
   "source": [
    "Import the plugin and all its functions:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56ee184d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# note: using plugins from the samples folder\n",
    "plugins_directory = \"../../../prompt_template_samples/\"\n",
    "\n",
    "funFunctions = kernel.add_plugin(parent_directory=plugins_directory, plugin_name=\"FunPlugin\")\n",
    "\n",
    "jokeFunction = funFunctions[\"Joke\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a9fc075a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KernelFunctionFromPrompt(metadata=KernelFunctionMetadata(name='Joke', plugin_name='FunPlugin', description='Generate a funny joke', parameters=[KernelParameterMetadata(name='input', description='Joke subject', default_value='', type_='', is_required=True, type_object=None, schema_data={'type': 'object', 'description': 'Joke subject'}, include_in_function_choices=True), KernelParameterMetadata(name='style', description='Give a hint about the desired joke style', default_value='', type_='', is_required=True, type_object=None, schema_data={'type': 'object', 'description': 'Give a hint about the desired joke style'}, include_in_function_choices=True)], is_prompt=True, is_asynchronous=True, return_parameter=KernelParameterMetadata(name='return', description='The completion result', default_value=None, type_='FunctionResult', is_required=True, type_object=None, schema_data=None, include_in_function_choices=True), additional_properties=None), invocation_duration_histogram=<opentelemetry.metrics._internal.instrument._ProxyHistogram object at 0x1144c75d0>, streaming_duration_histogram=<opentelemetry.metrics._internal.instrument._ProxyHistogram object at 0x1074c1290>, prompt_template=KernelPromptTemplate(prompt_template_config=PromptTemplateConfig(name='Joke', description='Generate a funny joke', template='WRITE EXACTLY ONE JOKE or HUMOROUS STORY ABOUT THE TOPIC BELOW\\n\\nJOKE MUST BE:\\n- G RATED\\n- WORKPLACE/FAMILY SAFE\\nNO SEXISM, RACISM OR OTHER BIAS/BIGOTRY\\n\\nBE CREATIVE AND FUNNY. I WANT TO LAUGH.\\nIncorporate the style suggestion, if provided: {{$style}}\\n+++++\\n\\n{{$input}}\\n+++++\\n', template_format='semantic-kernel', input_variables=[InputVariable(name='input', description='Joke subject', default='', is_required=True, json_schema='', allow_dangerously_set_content=False), InputVariable(name='style', description='Give a hint about the desired joke style', default='', is_required=True, json_schema='', allow_dangerously_set_content=False)], allow_dangerously_set_content=False, execution_settings={'default': PromptExecutionSettings(service_id=None, extension_data={'max_tokens': 1000, 'temperature': 0.9, 'top_p': 0.0, 'presence_penalty': 0.0, 'frequency_penalty': 0.0}, function_choice_behavior=None)}), allow_dangerously_set_content=False), prompt_execution_settings={'default': PromptExecutionSettings(service_id=None, extension_data={'max_tokens': 1000, 'temperature': 0.9, 'top_p': 0.0, 'presence_penalty': 0.0, 'frequency_penalty': 0.0}, function_choice_behavior=None)})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jokeFunction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "edd99fa0",
   "metadata": {},
   "source": [
    "How to use the plugin functions, e.g. generate a joke about \"_time travel to dinosaur age_\":\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6effe63b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why did the time traveler bring a suitcase full of sandwiches to the dinosaur age?\n",
      "\n",
      "Because he heard the T. rex was *terrible* at making lunch—tiny arms, no peanut butter skills, and absolutely no concept of crust removal!\n"
     ]
    }
   ],
   "source": [
    "from semantic_kernel.functions import KernelArguments\n",
    "\n",
    "joke = await kernel.invoke(\n",
    "    function=jokeFunction,\n",
    "    arguments=KernelArguments(input=\"time travel to dinosaur age\", style=\"super silly\"),\n",
    ")\n",
    "print(joke)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2281a1fc",
   "metadata": {},
   "source": [
    "Great, now that you know how to load a plugin from disk, let's show how you can [create and run a prompt function inline.](./03-prompt-function-inline.ipynb)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
